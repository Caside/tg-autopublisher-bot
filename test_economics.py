#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –Ω–æ–≤–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: —Ä–æ—Å—Å–∏–π—Å–∫–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ + —ç–∫–æ–Ω–æ–º–∏–∫–∞
"""

import asyncio
import logging
import sys
import os

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from deepseek_client import DeepSeekClient

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)

async def test_russian_sources():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –Ω–æ–≤—ã–µ —Ä–æ—Å—Å–∏–π—Å–∫–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Å —ç–∫–æ–Ω–æ–º–∏–∫–æ–π"""
    try:
        client = DeepSeekClient()

        print("üá∑üá∫ –¢–ï–°–¢ –†–û–°–°–ò–ô–°–ö–ò–• –ò–°–¢–û–ß–ù–ò–ö–û–í –° –≠–ö–û–ù–û–ú–ò–ö–û–ô")
        print("=" * 55)

        # –¢–µ—Å—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        print("\nüìä –ê–ù–ê–õ–ò–ó –ò–°–¢–û–ß–ù–ò–ö–û–í:")
        print("-" * 30)

        news_items = await client.news_collector.collect_news()

        if news_items:
            source_stats = {}
            economic_news = 0
            tech_news = 0
            science_news = 0

            for item in news_items:
                source_stats[item.source] = source_stats.get(item.source, 0) + 1

                # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ —Ç–µ–º–∞—Ç–∏–∫–µ
                title_lower = item.title.lower()
                if any(word in title_lower for word in ['–±–∏–∑–Ω–µ—Å', '—ç–∫–æ–Ω–æ–º–∏–∫', '—Ä—É–±–ª—å', '–±–∞–Ω–∫', '—Ñ–∏–Ω–∞–Ω—Å', '—Ä—ã–Ω–æ–∫', '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏']):
                    economic_news += 1
                elif any(word in title_lower for word in ['—Ç–µ—Ö–Ω–æ–ª–æ–≥', '–ø—Ä–æ–≥—Ä–∞–º–º', '—Ä–∞–∑—Ä–∞–±–æ—Ç', '–∏–∏', '–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π']):
                    tech_news += 1
                elif any(word in title_lower for word in ['–Ω–∞—É–∫', '–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω', '—É—á–µ–Ω—ã–µ', '–æ—Ç–∫—Ä—ã—Ç–∏']):
                    science_news += 1

            print(f"‚úÖ –í—Å–µ–≥–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {len(news_items)}")
            print(f"‚úÖ –†–∞–±–æ—á–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {len(source_stats)}")
            print()

            print("üìà –¢–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:")
            print(f"  üíº –≠–∫–æ–Ω–æ–º–∏–∫–∞/–±–∏–∑–Ω–µ—Å: {economic_news}")
            print(f"  üíª –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏/IT: {tech_news}")
            print(f"  üî¨ –ù–∞—É–∫–∞/–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è: {science_news}")
            print()

            print("üì° –ü–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º:")
            for source, count in sorted(source_stats.items()):
                source_type = "üíº" if any(x in source for x in ['vedomosti', 'rbc', 'kommersant', 'interfax']) else "üíª" if 'vc_tech' in source or 'cnews' in source else "üî¨"
                print(f"  {source_type} {source}: {count} –Ω–æ–≤–æ—Å—Ç–µ–π")

        # –¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ—Å—Ç–æ–≤
        print(f"\nü§ñ –¢–ï–°–¢ –ì–ï–ù–ï–†–ê–¶–ò–ò –ü–û–°–¢–û–í:")
        print("-" * 30)

        for test_num in range(1, 3):
            print(f"\nüîÑ –¢–µ—Å—Ç {test_num}:")

            post, prompt, headlines = await client.generate_hybrid_post(force_refresh=True)

            if post and headlines:
                # –ê–Ω–∞–ª–∏–∑ —Ç–µ–º–∞—Ç–∏–∫–∏ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
                economic_headlines = 0
                tech_headlines = 0
                science_headlines = 0

                for headline in headlines:
                    headline_lower = headline.lower()
                    if any(word in headline_lower for word in ['–±–∏–∑–Ω–µ—Å', '—ç–∫–æ–Ω–æ–º–∏–∫', '—Ä—É–±–ª—å', '–±–∞–Ω–∫', '—Ñ–∏–Ω–∞–Ω—Å', '—Ä—ã–Ω–æ–∫']):
                        economic_headlines += 1
                    elif any(word in headline_lower for word in ['—Ç–µ—Ö–Ω–æ–ª–æ–≥', '–ø—Ä–æ–≥—Ä–∞–º–º', '—Ä–∞–∑—Ä–∞–±–æ—Ç', '–∏–∏']):
                        tech_headlines += 1
                    elif any(word in headline_lower for word in ['–Ω–∞—É–∫', '–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω', '—É—á–µ–Ω—ã–µ']):
                        science_headlines += 1

                print(f"  üìä –¢–µ–º–∞—Ç–∏–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤:")
                print(f"    üíº –≠–∫–æ–Ω–æ–º–∏–∫–∞: {economic_headlines}")
                print(f"    üíª –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏: {tech_headlines}")
                print(f"    üî¨ –ù–∞—É–∫–∞: {science_headlines}")

                # –ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
                print(f"  üì∞ –ü—Ä–∏–º–µ—Ä—ã –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤:")
                for i, headline in enumerate(headlines[:3], 1):
                    print(f"    {i}. {headline[:70]}...")

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã LLM
                sections = post.split('\n\n')
                if len(sections) >= 2:
                    commentary = '\n\n'.join(sections[1:])
                    print(f"  üí≠ LLM —á–∞—Å—Ç—å: {len(commentary)} —Å–∏–º–≤–æ–ª–æ–≤")
                    print(f"  ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ: {'–î–∞' if commentary.strip().endswith(('.', '!', '?')) else '–ù–ï–¢'}")

        print(f"\nüéâ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
        print(f"–°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ —Å —Ä–æ—Å—Å–∏–π—Å–∫–∏–º–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏ –∏ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–º–∏ –Ω–æ–≤–æ—Å—Ç—è–º–∏!")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_russian_sources())